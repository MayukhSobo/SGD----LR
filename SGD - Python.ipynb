{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-06T05:50:43.660305Z",
     "start_time": "2018-10-06T05:50:43.655277Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from time import time\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-06T05:37:15.865651Z",
     "start_time": "2018-10-06T05:37:15.860893Z"
    }
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-06T05:37:31.162193Z",
     "start_time": "2018-10-06T05:37:31.100076Z"
    }
   },
   "outputs": [],
   "source": [
    "data = load_boston()\n",
    "sclr = StandardScaler()\n",
    "df = pd.DataFrame(sclr.fit_transform(data.data), columns=data.feature_names)\n",
    "df['price'] = data.target\n",
    "data = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-06T05:37:42.877604Z",
     "start_time": "2018-10-06T05:37:42.841776Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.419782</td>\n",
       "      <td>0.284830</td>\n",
       "      <td>-1.287909</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.144217</td>\n",
       "      <td>0.413672</td>\n",
       "      <td>-0.120013</td>\n",
       "      <td>0.140214</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.666608</td>\n",
       "      <td>-1.459000</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-1.075562</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.417339</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>0.194274</td>\n",
       "      <td>0.367166</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-0.492439</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.417342</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>1.282714</td>\n",
       "      <td>-0.265812</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>0.396427</td>\n",
       "      <td>-1.208727</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.416750</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>1.016303</td>\n",
       "      <td>-0.809889</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>0.416163</td>\n",
       "      <td>-1.361517</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.412482</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>1.228577</td>\n",
       "      <td>-0.511180</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-1.026501</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CRIM        ZN     INDUS      CHAS       NOX        RM       AGE  \\\n",
       "0 -0.419782  0.284830 -1.287909 -0.272599 -0.144217  0.413672 -0.120013   \n",
       "1 -0.417339 -0.487722 -0.593381 -0.272599 -0.740262  0.194274  0.367166   \n",
       "2 -0.417342 -0.487722 -0.593381 -0.272599 -0.740262  1.282714 -0.265812   \n",
       "3 -0.416750 -0.487722 -1.306878 -0.272599 -0.835284  1.016303 -0.809889   \n",
       "4 -0.412482 -0.487722 -1.306878 -0.272599 -0.835284  1.228577 -0.511180   \n",
       "\n",
       "        DIS       RAD       TAX   PTRATIO         B     LSTAT  price  \n",
       "0  0.140214 -0.982843 -0.666608 -1.459000  0.441052 -1.075562   24.0  \n",
       "1  0.557160 -0.867883 -0.987329 -0.303094  0.441052 -0.492439   21.6  \n",
       "2  0.557160 -0.867883 -0.987329 -0.303094  0.396427 -1.208727   34.7  \n",
       "3  1.077737 -0.752922 -1.106115  0.113032  0.416163 -1.361517   33.4  \n",
       "4  1.077737 -0.752922 -1.106115  0.113032  0.441052 -1.026501   36.2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-06T05:38:01.942092Z",
     "start_time": "2018-10-06T05:38:01.933866Z"
    }
   },
   "outputs": [],
   "source": [
    "def MSE(y: np.array, pred: np.array) -> float:\n",
    "    \"\"\"\n",
    "    It finds the mean squared error for\n",
    "    the converged intercept and weight\n",
    "    vector using the dataset. Mostly the\n",
    "    given dataset should be cross-validation\n",
    "    dataset to reduce the overfitting. The\n",
    "    following implementation was kept vectorized\n",
    "    so that we can use amazing speed of numpy.\n",
    "    \"\"\"\n",
    "\n",
    "    assert (y.shape[0] == pred.shape[0])\n",
    "    N = pred.shape[0]\n",
    "    y = y.reshape(N, 1)\n",
    "    pred = pred.reshape(N, 1)\n",
    "    residuals = y - pred\n",
    "    squared_errors = np.power(residuals, 2)\n",
    "    total_squared_errors = np.sum(squared_errors, axis=0)\n",
    "    mse = (1.0 / N) * total_squared_errors\n",
    "    return round(mse[0], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-06T05:38:15.091344Z",
     "start_time": "2018-10-06T05:38:15.087043Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(X, W, b):\n",
    "    N, d = X.shape\n",
    "    W = W.reshape(d, 1)\n",
    "    return (X @ W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-06T05:49:13.120795Z",
     "start_time": "2018-10-06T05:49:13.095337Z"
    }
   },
   "outputs": [],
   "source": [
    "def SGD(training_frame,\n",
    "        validation_frame=None,\n",
    "        use_validation_error=False,\n",
    "        random_state=42,\n",
    "        loss='squared_loss',\n",
    "        tol=1e-3,\n",
    "        learning_rate='adaptive',\n",
    "        eta0=0.01,\n",
    "        early_stopping=True,\n",
    "        no_iter_change=5,\n",
    "        max_iters=1000,\n",
    "        batch_size=100,\n",
    "        verbose=False,) -> dict:\n",
    "    \"\"\"\n",
    "    Non-regularized SGD for Linear Regression.\n",
    "    SGD stands for Stochastic Gradient Descent: the gradient\n",
    "    of the loss is estimated each sample at a time\n",
    "    and the model is updated along the way with a\n",
    "    decreasing strength schedule (aka learning rate).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    training_frame: np.ndarray:\n",
    "        The feature set for training from the dataset\n",
    "\n",
    "    validation_frame: np.array:\n",
    "        The feature set for cross validation from the dataset\n",
    "\n",
    "    use_validation_error: bool, default: False:\n",
    "        If validation error is to be used at all steps for errors\n",
    "\n",
    "    loss: str, default: 'squared_loss'\n",
    "        The loss function to be used\n",
    "\n",
    "    tol: float or None, default: 1e-3\n",
    "        Tolerance level of the stopping criteria\n",
    "\n",
    "    random_state: int\n",
    "        The random_state to be used for random seed\n",
    "\n",
    "    learning_rate: str, default: 'adaptive'\n",
    "        The type of learning rate.\n",
    "        If 'adaptive': make eta0 = eta0 / 5 if new\n",
    "                       error > old_error - tol\n",
    "        If 'constant': Don't change eta0\n",
    "\n",
    "    eta0: float, default: 0.01\n",
    "        The basic value of gradient multiplier, controlled by learning_rate\n",
    "\n",
    "    early_stopping: bool, default: True\n",
    "        If early stopping needs to be used to reduce the overfitting\n",
    "\n",
    "    no_iter_change: int, default: 5\n",
    "        If early_stopping is Ture, the this variable controls the number\n",
    "        of iterations fitting needs to be done even after no decrease in\n",
    "        error\n",
    "\n",
    "    max_iters: int, default: 1000\n",
    "        Maximum number of times the iteration would run if early_stopping\n",
    "        is False. At no point total iteration would go beyond max_iters.\n",
    "\n",
    "    batch_size: int, default: 100\n",
    "        Number of stochastic datapoints to reduce the computation\n",
    "\n",
    "    verbose: bool, default: False\n",
    "        If detailed progress needs to be should during the convergence\n",
    "        of the algorithm.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the initial W\n",
    "    np.random.seed(random_state)\n",
    "    multiplier = np.random.randint(low=5)\n",
    "    np.random.seed(random_state)\n",
    "    W = np.random.random(size=data.shape[1] - 1) * multiplier\n",
    "    W = W.reshape(data.shape[1] - 1, 1)\n",
    "\n",
    "    # Define the initial intercept\n",
    "    b = 0\n",
    "\n",
    "    pE = np.Inf  # Set the initial error to infinite\n",
    "\n",
    "    \n",
    "    # Check if we are using validation dataset also\n",
    "    if validation_frame is not None:\n",
    "        cv_X = validation_frame[:, 0:-1]\n",
    "        cv_y = validation_frame[:, -1]\n",
    "\n",
    "    for each_iter in range(1, max_iters):\n",
    "\n",
    "        start = time()\n",
    "\n",
    "        if verbose:\n",
    "            print(f'======= Converging for iter {each_iter} =======')\n",
    "\n",
    "        np.random.seed(random_state)\n",
    "        \n",
    "        # Creating stochastic samples from the bigger dataset of batch_size\n",
    "        sample = training_frame[np.random.choice(training_frame.shape[0], \n",
    "                                                 batch_size, replace=False), :]\n",
    "\n",
    "        X = sample[:, 0:-1]\n",
    "        y = sample[:, -1]\n",
    "        N, d = X.shape\n",
    "        y = y.reshape(N, 1)\n",
    "\n",
    "        # Store the previous weights and intercept\n",
    "        pW = W.reshape(d, 1)\n",
    "        pB = b\n",
    "\n",
    "        # Find the derivatives of the weight and intercept\n",
    "        dowW = y - predict(X, pW, pB)\n",
    "        dW = X.T @ dowW\n",
    "        dW = (-2.0 / N) * dW\n",
    "        dB = (-2.0 / N) * np.sum(dowW)\n",
    "\n",
    "        # Update the Weights and intercept\n",
    "        W = pW - (eta0 * dW)\n",
    "        b = pB - (eta0 * dB)\n",
    "\n",
    "        #########################################\n",
    "        \n",
    "        # Predicting for the current W and intercept for training data\n",
    "        pred = predict(X, W, b)\n",
    "        \n",
    "        # Predicting for the current W and intercept for validation data\n",
    "        if validation_frame is not None:\n",
    "            cv_pred = predict(cv_X, W, b)\n",
    "\n",
    "        # Store the previous error\n",
    "        error = pE\n",
    "        \n",
    "        # Check which loss is being used\n",
    "        if loss == 'squared_loss':\n",
    "            training_error = MSE(y, pred)  # Calculate the training loss\n",
    "            if validation_frame is not  None:\n",
    "                cv_error = MSE(cv_y, cv_pred)  # Calculate the validation loss if possible\n",
    "        else:\n",
    "            raise NotImplementedError(f\"Currently given loss = {loss} is not implemented\")\n",
    "        \n",
    "        # Define the base error depending on the ```use_validation_error``` variable\n",
    "        if use_validation_error and validation_frame is not None:\n",
    "            error = cv_error\n",
    "        else:\n",
    "            error = training_error\n",
    "\n",
    "        if early_stopping:\n",
    "            if error >= pE - tol and no_iter_change==0:\n",
    "                if verbose:\n",
    "                    print('!!!!!!!!!! Can not converge further !!!!!!!!!!')\n",
    "                    print(f'Training error {training_error}')\n",
    "                    if use_validation_error and cv_error:\n",
    "                        print(f'Training error {cv_error}')\n",
    "                return {\n",
    "                    'eta': eta0,\n",
    "                    'W': W,\n",
    "                    'b': b,\n",
    "                    'iter': each_iter,\n",
    "                    'train_MSE': training_error,\n",
    "                    'CV_MSE': None if not cv_error else cv_error\n",
    "                    }\n",
    "            elif error >= pE - tol and no_iter_change != 0:\n",
    "                no_iter_change -= 1\n",
    "                if learning_rate == 'adaptive':\n",
    "                    eta0 = eta0 / 5\n",
    "                    if verbose:\n",
    "                        print(f'Adaptive learning rate..New eta0 = {eta0}')\n",
    "        elif learning_rate == 'adaptive' and not early_stopping and error >= pE - tol:\n",
    "            if learning_rate == 'adaptive':\n",
    "                eta0 = eta0 / 5\n",
    "                if verbose:\n",
    "                    print(f'Adaptive learning rate..New eta0 = {eta0}')\n",
    "\n",
    "        pE = error\n",
    "        end = time()\n",
    "\n",
    "        if verbose:\n",
    "            print(f'\\n\\tTraining error: {error} \\n')\n",
    "            print(f' ======= Convergence took {round(end - start, 7)} secs ======= \\n\\n')\n",
    "    return {\n",
    "        'eta': eta0,\n",
    "        'W': W,\n",
    "        'b': b,\n",
    "        'iter': max_iters,\n",
    "        'train_MSE': training_error,\n",
    "        'CV_MSE': None if not cv_error else cv_error\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-06T06:05:28.637545Z",
     "start_time": "2018-10-06T06:05:28.629963Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data[:, 0:-1], data[:, -1], test_size=0.33, random_state=42)\n",
    "\n",
    "tf = np.hstack((X_train, y_train.reshape(len(y_train), 1)))\n",
    "vf = np.hstack((X_test, y_test.reshape(len(y_test), 1)))\n",
    "\n",
    "# tf = data[0:350]\n",
    "# vf = data[351:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-06T06:05:29.518199Z",
     "start_time": "2018-10-06T06:05:29.510974Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(339, 14)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-06T06:05:30.380044Z",
     "start_time": "2018-10-06T06:05:30.372950Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(167, 14)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-06T06:05:31.778229Z",
     "start_time": "2018-10-06T06:05:31.629832Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Converging for iter 1 =======\n",
      "\n",
      "\tTraining error: 9946.29227 \n",
      "\n",
      " ======= Convergence took 0.0011132 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 2 =======\n",
      "Adaptive learning rate..New eta0 = 0.2\n",
      "\n",
      "\tTraining error: 860160.98871 \n",
      "\n",
      " ======= Convergence took 0.0024242 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 3 =======\n",
      "Adaptive learning rate..New eta0 = 0.04\n",
      "\n",
      "\tTraining error: 1170033.33402 \n",
      "\n",
      " ======= Convergence took 0.0009961 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 4 =======\n",
      "\n",
      "\tTraining error: 379825.88581 \n",
      "\n",
      " ======= Convergence took 0.0008729 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 5 =======\n",
      "\n",
      "\tTraining error: 123712.27578 \n",
      "\n",
      " ======= Convergence took 0.0010848 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 6 =======\n",
      "\n",
      "\tTraining error: 40551.40311 \n",
      "\n",
      " ======= Convergence took 0.0012023 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 7 =======\n",
      "\n",
      "\tTraining error: 13461.33589 \n",
      "\n",
      " ======= Convergence took 0.000757 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 8 =======\n",
      "\n",
      "\tTraining error: 4584.80377 \n",
      "\n",
      " ======= Convergence took 0.0007961 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 9 =======\n",
      "\n",
      "\tTraining error: 1644.57022 \n",
      "\n",
      " ======= Convergence took 0.000771 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 10 =======\n",
      "\n",
      "\tTraining error: 650.63806 \n",
      "\n",
      " ======= Convergence took 0.001353 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 11 =======\n",
      "\n",
      "\tTraining error: 301.62134 \n",
      "\n",
      " ======= Convergence took 0.0008678 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 12 =======\n",
      "\n",
      "\tTraining error: 170.42743 \n",
      "\n",
      " ======= Convergence took 0.0009992 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 13 =======\n",
      "\n",
      "\tTraining error: 115.37967 \n",
      "\n",
      " ======= Convergence took 0.0009768 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 14 =======\n",
      "\n",
      "\tTraining error: 88.59093 \n",
      "\n",
      " ======= Convergence took 0.0007548 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 15 =======\n",
      "\n",
      "\tTraining error: 73.33982 \n",
      "\n",
      " ======= Convergence took 0.0007732 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 16 =======\n",
      "\n",
      "\tTraining error: 63.45939 \n",
      "\n",
      " ======= Convergence took 0.0007162 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 17 =======\n",
      "\n",
      "\tTraining error: 56.47257 \n",
      "\n",
      " ======= Convergence took 0.000684 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 18 =======\n",
      "\n",
      "\tTraining error: 51.26077 \n",
      "\n",
      " ======= Convergence took 0.0009391 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 19 =======\n",
      "\n",
      "\tTraining error: 47.24627 \n",
      "\n",
      " ======= Convergence took 0.000792 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 20 =======\n",
      "\n",
      "\tTraining error: 44.09075 \n",
      "\n",
      " ======= Convergence took 0.001349 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 21 =======\n",
      "\n",
      "\tTraining error: 41.57569 \n",
      "\n",
      " ======= Convergence took 0.0016329 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 22 =======\n",
      "\n",
      "\tTraining error: 39.55001 \n",
      "\n",
      " ======= Convergence took 0.0011401 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 23 =======\n",
      "\n",
      "\tTraining error: 37.90449 \n",
      "\n",
      " ======= Convergence took 0.0009921 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 24 =======\n",
      "\n",
      "\tTraining error: 36.55784 \n",
      "\n",
      " ======= Convergence took 0.0007448 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 25 =======\n",
      "\n",
      "\tTraining error: 35.4483 \n",
      "\n",
      " ======= Convergence took 0.001189 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 26 =======\n",
      "\n",
      "\tTraining error: 34.52832 \n",
      "\n",
      " ======= Convergence took 0.001055 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 27 =======\n",
      "\n",
      "\tTraining error: 33.76085 \n",
      "\n",
      " ======= Convergence took 0.0008261 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 28 =======\n",
      "\n",
      "\tTraining error: 33.1168 \n",
      "\n",
      " ======= Convergence took 0.0008759 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 29 =======\n",
      "\n",
      "\tTraining error: 32.57317 \n",
      "\n",
      " ======= Convergence took 0.001173 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 30 =======\n",
      "\n",
      "\tTraining error: 32.11168 \n",
      "\n",
      " ======= Convergence took 0.0006921 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 31 =======\n",
      "\n",
      "\tTraining error: 31.71769 \n",
      "\n",
      " ======= Convergence took 0.0006101 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 32 =======\n",
      "\n",
      "\tTraining error: 31.37947 \n",
      "\n",
      " ======= Convergence took 0.0009348 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 33 =======\n",
      "\n",
      "\tTraining error: 31.08753 \n",
      "\n",
      " ======= Convergence took 0.001524 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 34 =======\n",
      "\n",
      "\tTraining error: 30.83419 \n",
      "\n",
      " ======= Convergence took 0.0010202 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 35 =======\n",
      "\n",
      "\tTraining error: 30.61318 \n",
      "\n",
      " ======= Convergence took 0.0010493 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 36 =======\n",
      "\n",
      "\tTraining error: 30.4194 \n",
      "\n",
      " ======= Convergence took 0.0012028 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 37 =======\n",
      "\n",
      "\tTraining error: 30.24865 \n",
      "\n",
      " ======= Convergence took 0.0016429 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 38 =======\n",
      "\n",
      "\tTraining error: 30.09747 \n",
      "\n",
      " ======= Convergence took 0.0015988 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 39 =======\n",
      "\n",
      "\tTraining error: 29.963 \n",
      "\n",
      " ======= Convergence took 0.0010109 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 40 =======\n",
      "\n",
      "\tTraining error: 29.84285 \n",
      "\n",
      " ======= Convergence took 0.0011289 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 41 =======\n",
      "\n",
      "\tTraining error: 29.73505 \n",
      "\n",
      " ======= Convergence took 0.000711 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 42 =======\n",
      "\n",
      "\tTraining error: 29.63792 \n",
      "\n",
      " ======= Convergence took 0.0007107 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 43 =======\n",
      "\n",
      "\tTraining error: 29.55006 \n",
      "\n",
      " ======= Convergence took 0.00068 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 44 =======\n",
      "\n",
      "\tTraining error: 29.47029 \n",
      "\n",
      " ======= Convergence took 0.0006139 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 45 =======\n",
      "\n",
      "\tTraining error: 29.3976 \n",
      "\n",
      " ======= Convergence took 0.0007579 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 46 =======\n",
      "\n",
      "\tTraining error: 29.33114 \n",
      "\n",
      " ======= Convergence took 0.0007491 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 47 =======\n",
      "\n",
      "\tTraining error: 29.27018 \n",
      "\n",
      " ======= Convergence took 0.0006108 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 48 =======\n",
      "\n",
      "\tTraining error: 29.21409 \n",
      "\n",
      " ======= Convergence took 0.000663 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 49 =======\n",
      "\n",
      "\tTraining error: 29.16233 \n",
      "\n",
      " ======= Convergence took 0.00056 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 50 =======\n",
      "\n",
      "\tTraining error: 29.11442 \n",
      "\n",
      " ======= Convergence took 0.000658 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 51 =======\n",
      "\n",
      "\tTraining error: 29.06997 \n",
      "\n",
      " ======= Convergence took 0.00069 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 52 =======\n",
      "\n",
      "\tTraining error: 29.02861 \n",
      "\n",
      " ======= Convergence took 0.0011251 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 53 =======\n",
      "\n",
      "\tTraining error: 28.99005 \n",
      "\n",
      " ======= Convergence took 0.0009661 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 54 =======\n",
      "\n",
      "\tTraining error: 28.95401 \n",
      "\n",
      " ======= Convergence took 0.0006511 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 55 =======\n",
      "\n",
      "\tTraining error: 28.92025 \n",
      "\n",
      " ======= Convergence took 0.0007641 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 56 =======\n",
      "\n",
      "\tTraining error: 28.88856 \n",
      "\n",
      " ======= Convergence took 0.0007002 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 57 =======\n",
      "\n",
      "\tTraining error: 28.85876 \n",
      "\n",
      " ======= Convergence took 0.0006869 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 58 =======\n",
      "\n",
      "\tTraining error: 28.83068 \n",
      "\n",
      " ======= Convergence took 0.0007148 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 59 =======\n",
      "\n",
      "\tTraining error: 28.80417 \n",
      "\n",
      " ======= Convergence took 0.0006819 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 60 =======\n",
      "\n",
      "\tTraining error: 28.77911 \n",
      "\n",
      " ======= Convergence took 0.0006211 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 61 =======\n",
      "\n",
      "\tTraining error: 28.75538 \n",
      "\n",
      " ======= Convergence took 0.0007739 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 62 =======\n",
      "\n",
      "\tTraining error: 28.73287 \n",
      "\n",
      " ======= Convergence took 0.000751 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 63 =======\n",
      "\n",
      "\tTraining error: 28.7115 \n",
      "\n",
      " ======= Convergence took 0.0006061 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 64 =======\n",
      "\n",
      "\tTraining error: 28.69117 \n",
      "\n",
      " ======= Convergence took 0.0006499 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 65 =======\n",
      "\n",
      "\tTraining error: 28.6718 \n",
      "\n",
      " ======= Convergence took 0.0006082 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 66 =======\n",
      "\n",
      "\tTraining error: 28.65334 \n",
      "\n",
      " ======= Convergence took 0.0007942 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 67 =======\n",
      "\n",
      "\tTraining error: 28.63572 \n",
      "\n",
      " ======= Convergence took 0.0006783 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 68 =======\n",
      "\n",
      "\tTraining error: 28.61888 \n",
      "\n",
      " ======= Convergence took 0.0007138 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 69 =======\n",
      "\n",
      "\tTraining error: 28.60277 \n",
      "\n",
      " ======= Convergence took 0.000567 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 70 =======\n",
      "\n",
      "\tTraining error: 28.58734 \n",
      "\n",
      " ======= Convergence took 0.0006762 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 71 =======\n",
      "\n",
      "\tTraining error: 28.57255 \n",
      "\n",
      " ======= Convergence took 0.0006959 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 72 =======\n",
      "\n",
      "\tTraining error: 28.55836 \n",
      "\n",
      " ======= Convergence took 0.0007081 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 73 =======\n",
      "\n",
      "\tTraining error: 28.54474 \n",
      "\n",
      " ======= Convergence took 0.000684 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 74 =======\n",
      "\n",
      "\tTraining error: 28.53165 \n",
      "\n",
      " ======= Convergence took 0.0006783 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 75 =======\n",
      "\n",
      "\tTraining error: 28.51906 \n",
      "\n",
      " ======= Convergence took 0.0006399 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 76 =======\n",
      "\n",
      "\tTraining error: 28.50695 \n",
      "\n",
      " ======= Convergence took 0.0007071 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 77 =======\n",
      "\n",
      "\tTraining error: 28.49528 \n",
      "\n",
      " ======= Convergence took 0.0006571 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 78 =======\n",
      "\n",
      "\tTraining error: 28.48404 \n",
      "\n",
      " ======= Convergence took 0.0007949 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 79 =======\n",
      "\n",
      "\tTraining error: 28.47321 \n",
      "\n",
      " ======= Convergence took 0.000602 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 80 =======\n",
      "\n",
      "\tTraining error: 28.46275 \n",
      "\n",
      " ======= Convergence took 0.0007691 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 81 =======\n",
      "\n",
      "\tTraining error: 28.45266 \n",
      "\n",
      " ======= Convergence took 0.0007172 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 82 =======\n",
      "\n",
      "\tTraining error: 28.44292 \n",
      "\n",
      " ======= Convergence took 0.000757 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 83 =======\n",
      "\n",
      "\tTraining error: 28.4335 \n",
      "\n",
      " ======= Convergence took 0.0005991 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 84 =======\n",
      "\n",
      "\tTraining error: 28.4244 \n",
      "\n",
      " ======= Convergence took 0.000608 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 85 =======\n",
      "\n",
      "\tTraining error: 28.4156 \n",
      "\n",
      " ======= Convergence took 0.0005398 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 86 =======\n",
      "\n",
      "\tTraining error: 28.40709 \n",
      "\n",
      " ======= Convergence took 0.0006568 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 87 =======\n",
      "\n",
      "\tTraining error: 28.39886 \n",
      "\n",
      " ======= Convergence took 0.000648 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 88 =======\n",
      "\n",
      "\tTraining error: 28.39089 \n",
      "\n",
      " ======= Convergence took 0.000695 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 89 =======\n",
      "\n",
      "\tTraining error: 28.38317 \n",
      "\n",
      " ======= Convergence took 0.000634 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 90 =======\n",
      "\n",
      "\tTraining error: 28.37569 \n",
      "\n",
      " ======= Convergence took 0.0007529 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 91 =======\n",
      "\n",
      "\tTraining error: 28.36845 \n",
      "\n",
      " ======= Convergence took 0.0006552 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 92 =======\n",
      "\n",
      "\tTraining error: 28.36143 \n",
      "\n",
      " ======= Convergence took 0.0007551 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 93 =======\n",
      "\n",
      "\tTraining error: 28.35463 \n",
      "\n",
      " ======= Convergence took 0.0006726 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 94 =======\n",
      "\n",
      "\tTraining error: 28.34803 \n",
      "\n",
      " ======= Convergence took 0.0006549 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 95 =======\n",
      "\n",
      "\tTraining error: 28.34164 \n",
      "\n",
      " ======= Convergence took 0.0006611 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 96 =======\n",
      "\n",
      "\tTraining error: 28.33544 \n",
      "\n",
      " ======= Convergence took 0.0006301 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 97 =======\n",
      "\n",
      "\tTraining error: 28.32942 \n",
      "\n",
      " ======= Convergence took 0.0008059 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 98 =======\n",
      "\n",
      "\tTraining error: 28.32359 \n",
      "\n",
      " ======= Convergence took 0.0007172 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 99 =======\n",
      "\n",
      "\tTraining error: 28.31793 \n",
      "\n",
      " ======= Convergence took 0.0006549 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 100 =======\n",
      "\n",
      "\tTraining error: 28.31244 \n",
      "\n",
      " ======= Convergence took 0.000751 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 101 =======\n",
      "\n",
      "\tTraining error: 28.30711 \n",
      "\n",
      " ======= Convergence took 0.001152 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 102 =======\n",
      "\n",
      "\tTraining error: 28.30194 \n",
      "\n",
      " ======= Convergence took 0.0008898 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 103 =======\n",
      "\n",
      "\tTraining error: 28.29692 \n",
      "\n",
      " ======= Convergence took 0.0007029 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 104 =======\n",
      "\n",
      "\tTraining error: 28.29205 \n",
      "\n",
      " ======= Convergence took 0.0007539 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 105 =======\n",
      "\n",
      "\tTraining error: 28.28732 \n",
      "\n",
      " ======= Convergence took 0.0006649 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 106 =======\n",
      "\n",
      "\tTraining error: 28.28273 \n",
      "\n",
      " ======= Convergence took 0.0006652 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 107 =======\n",
      "\n",
      "\tTraining error: 28.27828 \n",
      "\n",
      " ======= Convergence took 0.0007482 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 108 =======\n",
      "\n",
      "\tTraining error: 28.27395 \n",
      "\n",
      " ======= Convergence took 0.0006511 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 109 =======\n",
      "\n",
      "\tTraining error: 28.26976 \n",
      "\n",
      " ======= Convergence took 0.0006659 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 110 =======\n",
      "\n",
      "\tTraining error: 28.26569 \n",
      "\n",
      " ======= Convergence took 0.000674 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 111 =======\n",
      "\n",
      "\tTraining error: 28.26174 \n",
      "\n",
      " ======= Convergence took 0.000596 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 112 =======\n",
      "\n",
      "\tTraining error: 28.2579 \n",
      "\n",
      " ======= Convergence took 0.000638 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 113 =======\n",
      "\n",
      "\tTraining error: 28.25418 \n",
      "\n",
      " ======= Convergence took 0.0006001 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 114 =======\n",
      "\n",
      "\tTraining error: 28.25057 \n",
      "\n",
      " ======= Convergence took 0.0007019 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 115 =======\n",
      "\n",
      "\tTraining error: 28.24707 \n",
      "\n",
      " ======= Convergence took 0.000674 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 116 =======\n",
      "\n",
      "\tTraining error: 28.24367 \n",
      "\n",
      " ======= Convergence took 0.0006819 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 117 =======\n",
      "\n",
      "\tTraining error: 28.24037 \n",
      "\n",
      " ======= Convergence took 0.000668 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 118 =======\n",
      "\n",
      "\tTraining error: 28.23718 \n",
      "\n",
      " ======= Convergence took 0.0006521 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 119 =======\n",
      "\n",
      "\tTraining error: 28.23408 \n",
      "\n",
      " ======= Convergence took 0.0006449 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 120 =======\n",
      "\n",
      "\tTraining error: 28.23107 \n",
      "\n",
      " ======= Convergence took 0.0005457 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 121 =======\n",
      "\n",
      "\tTraining error: 28.22816 \n",
      "\n",
      " ======= Convergence took 0.0006752 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 122 =======\n",
      "\n",
      "\tTraining error: 28.22533 \n",
      "\n",
      " ======= Convergence took 0.0008047 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 123 =======\n",
      "\n",
      "\tTraining error: 28.2226 \n",
      "\n",
      " ======= Convergence took 0.0006552 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 124 =======\n",
      "\n",
      "\tTraining error: 28.21995 \n",
      "\n",
      " ======= Convergence took 0.0006626 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 125 =======\n",
      "\n",
      "\tTraining error: 28.21738 \n",
      "\n",
      " ======= Convergence took 0.0007908 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 126 =======\n",
      "\n",
      "\tTraining error: 28.21489 \n",
      "\n",
      " ======= Convergence took 0.00067 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 127 =======\n",
      "\n",
      "\tTraining error: 28.21248 \n",
      "\n",
      " ======= Convergence took 0.0007241 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 128 =======\n",
      "\n",
      "\tTraining error: 28.21015 \n",
      "\n",
      " ======= Convergence took 0.0006628 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 129 =======\n",
      "\n",
      "\tTraining error: 28.2079 \n",
      "\n",
      " ======= Convergence took 0.0006819 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 130 =======\n",
      "\n",
      "\tTraining error: 28.20572 \n",
      "\n",
      " ======= Convergence took 0.0006638 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 131 =======\n",
      "\n",
      "\tTraining error: 28.20361 \n",
      "\n",
      " ======= Convergence took 0.0006461 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 132 =======\n",
      "\n",
      "\tTraining error: 28.20157 \n",
      "\n",
      " ======= Convergence took 0.0007951 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 133 =======\n",
      "\n",
      "\tTraining error: 28.1996 \n",
      "\n",
      " ======= Convergence took 0.000653 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 134 =======\n",
      "\n",
      "\tTraining error: 28.19769 \n",
      "\n",
      " ======= Convergence took 0.0006611 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 135 =======\n",
      "\n",
      "\tTraining error: 28.19586 \n",
      "\n",
      " ======= Convergence took 0.0006614 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 136 =======\n",
      "\n",
      "\tTraining error: 28.19408 \n",
      "\n",
      " ======= Convergence took 0.000654 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 137 =======\n",
      "\n",
      "\tTraining error: 28.19237 \n",
      "\n",
      " ======= Convergence took 0.0005698 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 138 =======\n",
      "\n",
      "\tTraining error: 28.19072 \n",
      "\n",
      " ======= Convergence took 0.0006781 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 139 =======\n",
      "\n",
      "\tTraining error: 28.18913 \n",
      "\n",
      " ======= Convergence took 0.0011299 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 140 =======\n",
      "\n",
      "\tTraining error: 28.1876 \n",
      "\n",
      " ======= Convergence took 0.0007303 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 141 =======\n",
      "\n",
      "\tTraining error: 28.18612 \n",
      "\n",
      " ======= Convergence took 0.0007911 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 142 =======\n",
      "\n",
      "\tTraining error: 28.1847 \n",
      "\n",
      " ======= Convergence took 0.000761 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 143 =======\n",
      "\n",
      "\tTraining error: 28.18334 \n",
      "\n",
      " ======= Convergence took 0.0006599 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 144 =======\n",
      "\n",
      "\tTraining error: 28.18202 \n",
      "\n",
      " ======= Convergence took 0.0008409 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 145 =======\n",
      "\n",
      "\tTraining error: 28.18076 \n",
      "\n",
      " ======= Convergence took 0.0008001 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 146 =======\n",
      "\n",
      "\tTraining error: 28.17955 \n",
      "\n",
      " ======= Convergence took 0.0009859 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 147 =======\n",
      "\n",
      "\tTraining error: 28.1784 \n",
      "\n",
      " ======= Convergence took 0.001261 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 148 =======\n",
      "\n",
      "\tTraining error: 28.17729 \n",
      "\n",
      " ======= Convergence took 0.000958 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 149 =======\n",
      "\n",
      "\tTraining error: 28.17622 \n",
      "\n",
      " ======= Convergence took 0.000391 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 150 =======\n",
      "\n",
      "\tTraining error: 28.17521 \n",
      "\n",
      " ======= Convergence took 0.000422 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 151 =======\n",
      "Adaptive learning rate..New eta0 = 0.008\n",
      "\n",
      "\tTraining error: 28.17424 \n",
      "\n",
      " ======= Convergence took 0.0008781 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 152 =======\n",
      "Adaptive learning rate..New eta0 = 0.0016\n",
      "\n",
      "\tTraining error: 28.17405 \n",
      "\n",
      " ======= Convergence took 0.0007312 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 153 =======\n",
      "Adaptive learning rate..New eta0 = 0.00032\n",
      "\n",
      "\tTraining error: 28.17401 \n",
      "\n",
      " ======= Convergence took 0.0007219 secs ======= \n",
      "\n",
      "\n",
      "======= Converging for iter 154 =======\n",
      "!!!!!!!!!! Can not converge further !!!!!!!!!!\n",
      "Training error 14.39605\n",
      "Training error 28.174\n",
      "{'eta': 0.00032, 'W': array([[-0.56705723],\n",
      "       [-0.6936833 ],\n",
      "       [ 0.41711964],\n",
      "       [ 0.02070669],\n",
      "       [-0.88370291],\n",
      "       [ 4.25509286],\n",
      "       [-0.75169972],\n",
      "       [-1.40576966],\n",
      "       [ 0.51470419],\n",
      "       [-0.88535042],\n",
      "       [-1.30156968],\n",
      "       [ 0.52465277],\n",
      "       [-4.65460317]]), 'b': 21.63427206247121, 'iter': 154, 'train_MSE': 14.39605, 'CV_MSE': 28.174}\n"
     ]
    }
   ],
   "source": [
    "print(SGD(training_frame=tf, validation_frame=vf,\n",
    "          random_state=42, verbose=True, max_iters=10000,\n",
    "          learning_rate='adaptive', eta0=1.0, use_validation_error=True, early_stopping=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-06T06:06:46.066647Z",
     "start_time": "2018-10-06T06:06:46.042609Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.724023437339785\n"
     ]
    }
   ],
   "source": [
    "clf = LinearRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "print(mean_squared_error(y_test, pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
